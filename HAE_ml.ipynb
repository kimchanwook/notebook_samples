{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import struct\n",
    "import time\n",
    "import csv\n",
    "import pickle\n",
    "import math\n",
    "import gc\n",
    "\n",
    "import numpy                  as np\n",
    "import pandas                 as pd\n",
    "import matplotlib             as mpl\n",
    "import matplotlib.pyplot      as plt\n",
    "import tensorflow             as tf\n",
    "from   tensorflow             import keras\n",
    "\n",
    "import scipy\n",
    "from   scipy             import interpolate\n",
    "from   scipy.interpolate import CubicSpline, splev, splrep, PPoly\n",
    "from   scipy.optimize    import curve_fit, minimize\n",
    "\n",
    "# from   scipy.stats            import kde\n",
    "# from   mpl_toolkits           import mplot3d\n",
    "# from   mpl_toolkits.mplot3d   import Axes3D\n",
    "\n",
    "# sys.path.insert(0, \"/home/chan/2_ROOT/0_FROST/0_FROSTpython\")\n",
    "# from   rbDST2dict import rbDST2dict_chan as frz\n",
    "# from   rbDST2dict.rbDST2dict_chan import rbDST2dict_chan as frz\n",
    "# from   rbDST2dict             import rbDST2dict_chan as frz      #rbDST2dict=dir, rbDST2dict.py=module, rbDST2dict()=class\n",
    "                                                                 #you need to specify the folder -> \"from rbDST2dict\"\n",
    "\n",
    "#To increase the cell width + load Images\n",
    "from IPython.core.display import display, HTML, Image\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style\n",
    "#Pandas options\n",
    "pd.options.display.max_columns = None\n",
    "# pd.options.display.max_rows    = 100\n",
    "\n",
    "#Plotting Config\n",
    "mpl.style.use(\"default\")\n",
    "mpl.rcParams[\"axes.facecolor\"] = \"#EAEAF2\" \n",
    "mpl.rcParams['figure.dpi']     = 100 \n",
    "mpl.rcParams['savefig.dpi']    = 100 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Target Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Training Data (MUST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Notes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "(NOTES)\n",
    "* As # of butanol training increased (while same # of carbon training events), more events were classified as butanol\n",
    "  events. $\\rightarrow$ Weird carbon peack at ambiguous region disappeared which is good.\n",
    "  * My guess is that ratio of training data for butanol vs training data for carbon must be same as the ratio of \n",
    "    real butanol events vs real carbon events:\n",
    "    $$ \\frac{\\text{# butanol train events}}{\\text{# carbon train events}} = \\frac{\\text{# butanol events}}{\\text{# carbon events}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Code (MUST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Butanol\n",
    "df_butanol_train = df_GMSH[(df_GMSH[\"z\"] >= -3.3) & (df_GMSH[\"z\"] <= 3.3)]\n",
    "#Carbon\n",
    "df_carbon_train = df_GMSH[(df_GMSH[\"z\"] >= 5.5) & (df_GMSH[\"z\"] <= 7.0)]\n",
    "#Polythene\n",
    "df_polythene_train = df_GMSH[(df_GMSH[\"z\"] >= 15) & (df_GMSH[\"z\"] <= 17.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of carbon training events    =  20000\n",
      "# of butanol training events   =  135899\n",
      "# of polythene training events =  21887\n"
     ]
    }
   ],
   "source": [
    "num_carb_train = 20000\n",
    "num_buta_train = int(len(df_butanol_train) / len(df_carbon_train) * num_carb_train)\n",
    "num_poly_train = int(len(df_polythene_train) / len(df_carbon_train) * num_carb_train)\n",
    "\n",
    "print(\"# of carbon training events    = \", num_carb_train)\n",
    "print(\"# of butanol training events   = \", num_buta_train)\n",
    "print(\"# of polythene training events = \", num_poly_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Select Random points for reduced training data\n",
    "df_butanol_train   = df_butanol_train.sample(num_buta_train)\n",
    "df_carbon_train    = df_carbon_train.sample(num_carb_train)\n",
    "df_polythene_train = df_polythene_train.sample(num_poly_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(df_butanol_train)   = 135899\n",
      "len(df_carbon_train)    = 20000\n",
      "len(df_polythene_train) = 21887\n"
     ]
    }
   ],
   "source": [
    "print(\"len(df_butanol_train)   = {:d}\".format(len(df_butanol_train)))\n",
    "print(\"len(df_carbon_train)    = {:d}\".format(len(df_carbon_train)))\n",
    "print(\"len(df_polythene_train) = {:d}\".format(len(df_polythene_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Training data histrogram (CHECK)\n",
    "training_hist_TS = plt.figure(figsize=(10,10))\n",
    "plt.hist(df_butanol_train.z, alpha=0.5, bins=100, histtype='stepfilled', label=\"Butanol Training\", color=\"#55A868\")\n",
    "plt.hist(df_carbon_train.z, alpha=0.5, bins=100, histtype='stepfilled', label=\"Carbon Training\", color=\"#C44E52\")\n",
    "plt.hist(df_polythene_train.z, alpha=0.5, bins=100, histtype='stepfilled', label=\"Polythene Training\", color=\"#4C72B0\")\n",
    "\n",
    "plt.xlabel(\"Z-Vertex Position (cm)\", fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "training_hist_TS.savefig(\"training_hist_TS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Ground Truth column - train labels\n",
    "df_butanol_train[\"truth\"]   = 0\n",
    "df_carbon_train[\"truth\"]    = 1\n",
    "df_polythene_train[\"truth\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Combine trainig data of butanol + carbon + polythene\n",
    "df_train_all = pd.concat([df_butanol_train, df_carbon_train, df_polythene_train])\n",
    "\n",
    "#Separate df for ground truth - train label\n",
    "df_train_label = pd.DataFrame(df_train_all[\"truth\"])\n",
    "\n",
    "#Drop groun truth column in training data\n",
    "df_train_all.drop(columns=[\"truth\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pid', 'E', 'px', 'py', 'pz', 'betac', 'mass', 'betam', 'epho', 'x',\n",
       "       'y', 'z', 'TRIGBITS', 'el_px', 'el_py', 'el_pz', 'el_E', 'timediff',\n",
       "       'runNum', 'p_abs', 'el_p_abs', 'mmsq_pi0', 'el_mmsq_pi0', 'theta',\n",
       "       'phi', 'sector', 'tof_pad', 'beta_diff', 'w', 'cthe_cm', 'tar_Pol',\n",
       "       'tar_Pol_stat', 'tar_Pol_sys', 'tar_Pol_sign', 'bm_helicity', 'pol_pho',\n",
       "       'pol_pho_stat', 'T_fin', 'el_pc_p_abs', 'el_pc_mmsq_pi0', 'phi_sec'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GMSH.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Drop unwanted columns\n",
    "\n",
    "df_train_all.drop(columns=['pid', 'E', 'px', 'py', 'pz', 'betac', 'mass', 'betam', 'TRIGBITS',\n",
    "                           'timediff', 'runNum', 'p_abs', 'mmsq_pi0',\n",
    "                           'sector', 'tof_pad', 'beta_diff', 'w',\n",
    "                           'cthe_cm', 'tar_Pol',\n",
    "                           'tar_Pol_stat', 'tar_Pol_sys', 'tar_Pol_sign', 'bm_helicity', 'pol_pho',\n",
    "                           'pol_pho_stat'], inplace=True)\n",
    "\n",
    "\n",
    "# df_train_all.drop(columns=['pid', 'E', 'px', 'py', 'pz', 'betac', 'mass', 'betam', 'scPdHt', 'TRIGBITS',\n",
    "#                            'timediff', 'runNum', 'p_abs', 'mmsq_pi0',\n",
    "#                            'sector', 'tof_pad', 'beta_diff', 'w', 'beta_cm',\n",
    "#                            'gamma_cm', 'pz_cm', 'p_cm_abs', 'theta_cm', 'cthe_cm', 'tar_Pol',\n",
    "#                            'tar_Pol_stat', 'tar_Pol_sys', 'tar_Pol_sign', 'bm_helicity', 'pol_pho',\n",
    "#                            'pol_pho_stat'], inplace=True)\n",
    "\n",
    "# df_train_all.drop(columns=[\"pid\", \"ntrk\", \"scPdHt\", \"TRIGBITS\", \"runNum\", \"p_abs\", \n",
    "#                            \"beta_diff\", \"sector\", \"tof_pad\", \"beta_cm\", \"gamma_cm\", \"pz_cm\", \"p_cm_abs\",\n",
    "#                            \"theta_cm\", \"cthe_cm\", \"tar_Pol\", \"tar_Pol_sign\", \"bm_helicity\", \"pol_pho\", \\\n",
    "#                            'T_pred', 'ice_pred', 'T_fin', 'sf', 'tar_Pol_stat', 'tar_Pol_sys', 'pol_pho_stat'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Drop when doing 2nd time\n",
    "# df_train_all.drop(columns=[\"T_pred\", \"ice_pred\", \"T_fin\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['epho', 'x', 'y', 'z', 'el_px', 'el_py', 'el_pz', 'el_E', 'el_p_abs',\n",
       "       'el_mmsq_pi0', 'theta', 'phi', 'T_fin', 'el_pc_p_abs', 'el_pc_mmsq_pi0',\n",
       "       'phi_sec'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Convert to numpy ndarray \n",
    "train_all   = df_train_all.values\n",
    "train_label = df_train_label.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177786\n",
      "177786\n",
      "(177786, 16)\n",
      "(177786, 1)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_all))\n",
    "print(len(train_label))\n",
    "print(train_all.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Study Correlation of parameters (NONEED)\n",
    "# df_train_all.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Seaborn Heatmap (NONEED)\n",
    "# sns.set(font_scale=1.5)\n",
    "# g9a_heatmap = plt.figure(figsize=(13,13))\n",
    "# #Remove Upper Right Triangle\n",
    "# mask=np.zeros_like(df_train_all.corr())\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# #Set the Upper Right Triangle as white blank spaces\n",
    "# with sns.axes_style(\"white\"):\n",
    "#     sns.heatmap(df_train_all.corr(), vmin=-1, vmax=1, mask=mask)\n",
    "# plt.show()\n",
    "# g9a_heatmap.savefig(\"g9a_heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Test Data (MUST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Code (MUST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#drop the columns that df_train_all dropped already\n",
    "\n",
    "df_GMSH_ml = df_GMSH.drop(columns=['pid', 'E', 'px', 'py', 'pz', 'betac', 'mass', 'betam', 'TRIGBITS',\n",
    "                           'timediff', 'runNum', 'p_abs', 'mmsq_pi0',\n",
    "                           'sector', 'tof_pad', 'beta_diff', 'w',\n",
    "                           'cthe_cm', 'tar_Pol',\n",
    "                           'tar_Pol_stat', 'tar_Pol_sys', 'tar_Pol_sign', 'bm_helicity', 'pol_pho',\n",
    "                           'pol_pho_stat'])\n",
    "\n",
    "\n",
    "# df_GMSH_ml = df_GMSH.drop(columns=['pid', 'E', 'px', 'py', 'pz', 'betac', 'mass', 'betam', 'scPdHt', 'TRIGBITS',\n",
    "#                            'timediff', 'runNum', 'p_abs', 'mmsq_pi0',\n",
    "#                            'sector', 'tof_pad', 'beta_diff', 'w', 'beta_cm',\n",
    "#                            'gamma_cm', 'pz_cm', 'p_cm_abs', 'theta_cm', 'cthe_cm', 'tar_Pol',\n",
    "#                            'tar_Pol_stat', 'tar_Pol_sys', 'tar_Pol_sign', 'bm_helicity', 'pol_pho',\n",
    "#                            'pol_pho_stat'])\n",
    "\n",
    "# df_GMSH_ml = df_GMSH.drop(columns=[\"pid\", \"ntrk\", \"scPdHt\", \"TRIGBITS\", \"runNum\", \"p_abs\", \n",
    "#                            \"beta_diff\", \"sector\", \"tof_pad\", \"beta_cm\", \"gamma_cm\", \"pz_cm\", \"p_cm_abs\",\n",
    "#                            \"theta_cm\", \"cthe_cm\", \"tar_Pol\", \"tar_Pol_sign\", \"bm_helicity\", \"pol_pho\", \\\n",
    "#                            'T_pred', 'ice_pred', 'T_fin', 'sf', 'tar_Pol_stat', 'tar_Pol_sys', 'pol_pho_stat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['epho', 'x', 'y', 'z', 'el_px', 'el_py', 'el_pz', 'el_E', 'el_p_abs', 'el_mmsq_pi0', 'theta', 'phi', 'T_fin', 'el_pc_p_abs', 'el_pc_mmsq_pi0', 'phi_sec']\n",
      "['epho', 'x', 'y', 'z', 'el_px', 'el_py', 'el_pz', 'el_E', 'el_p_abs', 'el_mmsq_pi0', 'theta', 'phi', 'T_fin', 'el_pc_p_abs', 'el_pc_mmsq_pi0', 'phi_sec']\n"
     ]
    }
   ],
   "source": [
    "#Change order of columns so that columns of training data and test data matchesÂ¶\n",
    "df_train_all_cols = df_train_all.columns.tolist()\n",
    "df_GMSH_ml = df_GMSH_ml[df_train_all_cols]\n",
    "\n",
    "print(df_train_all_cols)\n",
    "print(df_GMSH_ml.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#convert df_GPID_MVRT to numpy ndarry\n",
    "test_all = df_GMSH_ml.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Summary of training + test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# So far we have the following data sets: (NOTES)\n",
    "# * test_all = test data set \n",
    "#   * df_GMSH_ml\n",
    "# * train_all = training data set\n",
    "#   * df_train_all \n",
    "# * train_label  = trainig label (true values)\n",
    "#   * df_train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Build Model + Prediction (keras) (MUST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Notes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "__`Basics of NN`__ (NOTES)\n",
    "* Each neural netwrork operates on input data as follow:\n",
    "  $$ output = relu(dot(W, input) + b) $$\n",
    "  * $b=trainable\\ parameter$ are tensors that is attribute of the _bias_\n",
    "  * $W=weights$ (_coefficients_) - tensor that is an attribute of the _kernel_ \n",
    "    * Initially, these weights are filled with small randome values, _random initialization_\n",
    "    * gradual adjustment of these weights after each iteration in _training loop_ = training the model data\n",
    "      1. Draw training samples _x_ and corresponding targets _y_\n",
    "      2. Run the network on _x_ (step called _forward pass_) to obtain predictions _y_pred_\n",
    "      3. Compute the loss of the network on the batch: a measure of the mismatch between _y_pred_ and _y_.\n",
    "      4. __Optimizer__: Update all weights of the network in a way that slightly reduces the loss on this batch. \n",
    "        * How can you compute how the coefficient should be altered? improved?\n",
    "          1. Naive solution\n",
    "            * freeze all weights in the network except the one scalar coefficient being considered and try new values\n",
    "              untill it improves. \n",
    "          2. Better solution (_stochastic gradient descent_ SGD algorithm)\n",
    "            * Since all tensor operations are _differentiable_, compute _graduent_ of the loss function with regards \n",
    "              to the network's coefficients/parameters. Then, move the coefficients in the opposite direction from the\n",
    "              gradient, thus decreasing the loss: \n",
    "              $$ W -= step\\ *\\ gradient $$\n",
    "              $$ new W = old W - learning rate * gradient $$\n",
    "            * step size = learning rate\n",
    "            * Find the minimum and alter the coefficients toward minimum.\n",
    "            * _stochastic_ refers to the fact that each batch of data is drawn at random.\n",
    "          3. SGD with momentum\n",
    "            * use gradient of not only the current value (current velocity), but also the past value (past velocity). Thus,\n",
    "              it allows the see local minimum + global minimum.\n",
    "            \n",
    "* __Optimizer__ and __loss function__ are what determines the NN algorithm - `where physics can be applied`.\n",
    "  * I assume most of the optimizers use statistical methods using traing data and computing relations between parameters of\n",
    "    training data to find a way to best update Weights.\n",
    "  * However, if you have external knowledge (physics in our case: __`relativistic kinematics`__) about the system that you\n",
    "    can put as constraints when optimizing, it will yield better results:\n",
    "    * Scattering angle limitation\n",
    "      * For example, at certain forbidden angles, angles weigh less than momentum, energy, ... $\\rightarrow$ update weights \n",
    "        in such a way that the layers use parameters such as momentum, energy , etc more than scattering angles. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "__`Code Explanation`__ (NOTES)\n",
    "* __keras.Sequential__ model is a linear stack of layers\n",
    "* __tf.keras.layers.Dense__ \n",
    "  * the network will consist of two dense (fully-connected) neural layers. \n",
    "    * 1st dense neural layer has 15 nodes since we have 15 parameters \n",
    "      * tf.nn.relu = Re(ctified) L(inear) U(nit)\n",
    "        * As results from each layer needs to yield a specific representation of result (i.e. 0 or 1), there\n",
    "          for we need to rectify the result using a function and in this case, a linear function.\n",
    "    * 2nd dense neural layer has 3-node softmax layer - `This is where __prediction__ happens`\n",
    "      * tf.nn.softmax = For each event, it returns an array of 3 probability scores that sum to 1 - Normalisation of \n",
    "        sum(input)=1\n",
    "        * each node contains a score that indicates the probability that the current event belong to butanol, carbon,\n",
    "          or polythene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (NOTES)\n",
    "# * fit() method is to train the model to fit to the data\n",
    "# * epochs = 5 means you train that 5 times\n",
    "# * Accruracy increased as more trainings are done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Code (MUST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Layer Setup\n",
    "#    -linear staack of layers\n",
    "#    -Specify input_shape in the first layer if you want to use model.save() function\n",
    "#        -input_shape = (# of columns, )\n",
    "model_ts = keras.Sequential()\n",
    "# model_ts.add(keras.layers.Dense(100, activation=tf.nn.relu))\n",
    "model_ts.add(keras.layers.Dense(15, activation=tf.nn.relu))\n",
    "model_ts.add(keras.layers.Dense(15, activation=tf.nn.relu))\n",
    "# model_ts.add(keras.layers.Dense(15, activation=tf.nn.relu))\n",
    "model_ts.add(keras.layers.Dense(3, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Compile: Optimizer + Loss function\n",
    "model_ts.compile(optimizer=tf.optimizers.Adam(),\n",
    "                 loss     = \"sparse_categorical_crossentropy\",\n",
    "                 metrics  = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5556/5556 [==============================] - 10s 2ms/step - loss: 0.1344 - accuracy: 0.9693\n",
      "Epoch 2/3\n",
      "5556/5556 [==============================] - 8s 1ms/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 3/3\n",
      "5556/5556 [==============================] - 7s 1ms/step - loss: 6.4710e-04 - accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5f8f384f98>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Traing\n",
    "#    -fit() method is to train the model to fit to the data\n",
    "#    -epochs = 5 means you train that 5 times\n",
    "#    -Accruracy increased as more trainings are done\n",
    "model_ts.fit(train_all, train_label, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Predict\n",
    "predictions = model_ts.predict(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#predictions_list is a list of final predictions of target on test_all data\n",
    "predictions_list = []\n",
    "for i in range(0, len(predictions)):\n",
    "    predictions_list.append(np.argmax(predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Append predicted values (predictions_list) to df\n",
    "df_GMSH[\"T_pred\"] = pd.Series(predictions_list, index=df_GMSH.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Target Prediction (CHECK)\n",
    "ML_target_sep, [ax1, ax2, ax3] = plt.subplots(3, 1, sharex=True, figsize=(15,15))\n",
    "\n",
    "#target label\n",
    "target_label = df_GMSH.T_pred.unique()\n",
    "\n",
    "for i in target_label:\n",
    "    hit = df_GMSH[df_GMSH.T_pred == i]\n",
    "    if i == 0:\n",
    "        target = \"Butanol\"\n",
    "        n_buta, b_buta, p_buta = ax1.hist(hit.z, alpha=0.5, bins=500, histtype='bar', label=target) \n",
    "    elif i== 1:\n",
    "        target = \"Carbon\"\n",
    "        ax2.hist(hit.z, alpha=0.5, bins=500, histtype='bar', label=target) \n",
    "    elif i==2:\n",
    "        target = \"Polythene\"\n",
    "        ax3.hist(hit.z, alpha=0.5, bins=500, histtype='bar', label=target) \n",
    "\n",
    "#Grids\n",
    "for i in [ax1, ax2, ax3]:\n",
    "    i.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "    i.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "    i.grid(b=True, which=\"major\", color=\"gray\", linewidth=1.0, linestyle=\"--\")\n",
    "    i.grid(b=True, which=\"minor\", color=\"gray\", linewidth=0.5, linestyle=\"--\")        \n",
    "        \n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "ax3.legend()\n",
    "plt.xlabel(\"Z-Vertex Position (cm)\")\n",
    "plt.xlim(-10,20)\n",
    "\n",
    "#Spacing 0\n",
    "ML_target_sep.subplots_adjust(hspace=0.)\n",
    "\n",
    "plt.show()\n",
    "# ML_target_sep.savefig(\"./run_period_1/ML_target_sep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Target Prediction - on Same axes (CHECK)\n",
    "ML_TS_pred   = plt.figure(figsize=(15,10))\n",
    "\n",
    "#Bins\n",
    "bin_num = int(0.15*np.sqrt(len(df_GMSH)))\n",
    "\n",
    "#Plot\n",
    "n_buta, b_buta, p_buta = plt.hist(df_GMSH[df_GMSH[\"T_pred\"]==0][\"z\"], bins=bin_num, label=\"Butanol\", \\\n",
    "                                  alpha=0.7, color=\"#55A868\")\n",
    "n_carb, b_carb, p_carb = plt.hist(df_GMSH[df_GMSH[\"T_pred\"]==1][\"z\"], bins=bin_num, label=\"Carbon\", \\\n",
    "                                  alpha=0.7, color=\"#C44E52\")\n",
    "\n",
    "#Stats\n",
    "peak_buta = b_buta[np.argmax(n_buta)]\n",
    "mean_buta = df_GMSH[df_GMSH[\"T_pred\"]==0][\"z\"].astype(float).mean()\n",
    "std_buta  = df_GMSH[df_GMSH[\"T_pred\"]==0][\"z\"].astype(float).std()\n",
    "peak_carb = b_carb[np.argmax(n_carb)]\n",
    "mean_carb = df_GMSH[df_GMSH[\"T_pred\"]==1][\"z\"].astype(float).mean()\n",
    "std_carb  = df_GMSH[df_GMSH[\"T_pred\"]==1][\"z\"].astype(float).std()\n",
    "\n",
    "#Texts\n",
    "plt.text(0.03, 0.75, \"Butanol \\n Peak {:>10.3f} \\n $\\mu$ {:>15.3f} \\n $\\sigma$ {:>15.3f}\" \\\n",
    "         .format(peak_buta, mean_buta, std_buta), \\\n",
    "         fontsize=20, bbox=dict(facecolor='none', pad=5.0), transform=plt.gca().transAxes)\n",
    "plt.text(0.03, 0.55, \"Carbon \\n Peak {:>10.3f} \\n $\\mu$ {:>15.3f} \\n $\\sigma$ {:>15.3f}\" \\\n",
    "         .format(peak_carb, mean_carb, std_carb), \\\n",
    "         fontsize=20, bbox=dict(facecolor='none', pad=5.0), transform=plt.gca().transAxes)\n",
    "\n",
    "\n",
    "#Grids\n",
    "plt.axes().xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "plt.axes().yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "plt.grid(b=True, which=\"major\", color=\"gray\", linewidth=1.0, linestyle=\"--\")\n",
    "plt.grid(b=True, which=\"minor\", color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "#Y-Axis Scaling\n",
    "def adjust_y_axis(x, pos):\n",
    "    return \"{:.0f}\".format(x/10000)\n",
    "plt.gca().yaxis.set_major_formatter(mpl.ticker.FuncFormatter(adjust_y_axis))\n",
    "        \n",
    "plt.xlim(-6, 10)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(\"Z-Vertex Position (cm)\", fontsize=25)\n",
    "plt.ylabel(\"Counts $(x10^4)$\", fontsize=25)\n",
    "plt.legend(fontsize=25)\n",
    "plt.show()\n",
    "# ML_TS_pred.savefig(\"ML_TS_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Butanol vs Carbon mmsp (CHECK)\n",
    "g9a_mmsq_hist_pred = plt.figure(figsize=(15,12))\n",
    "\n",
    "target_label = df_GMSH.T_pred.unique()\n",
    "ax=plt.axes()\n",
    "\n",
    "for i in target_label:\n",
    "    hit = df_GMSH[df_GMSH.T_pred == i]\n",
    "    if i == 0:\n",
    "        target = \"Butanol\"\n",
    "        n_buta, b_buta, p_buta = ax.hist(hit.mmsq_pi0, alpha=0.5, bins=1000, histtype='step', label=target, \\\n",
    "                                         color='#55A868', lw=3) \n",
    "        bin_max_buta = np.argmax(n_buta)\n",
    "        buta_peak    = b_buta[bin_max_buta]\n",
    "        #plt.axvline(x = b[bin_max_buta], linestyle=\"--\", color = \"g\")\n",
    "    elif i== 1:\n",
    "        target = \"Carbon\"\n",
    "        n_carb, b_carb, p_carb = ax.hist(hit.mmsq_pi0, alpha=0.5, bins=b_buta, histtype='step', label=target, \\\n",
    "                                         color='#C44E52', lw=3) \n",
    "        bin_max_carb = np.argmax(n_carb)\n",
    "        carb_peak    = b_carb[bin_max_carb]\n",
    "        #plt.axvline(x = b[bin_max_carb], linestyle=\"--\", color = \"r\")\n",
    "    elif i==2:\n",
    "        target = \"Polythene\"\n",
    "        \n",
    "#Texts\n",
    "plt.text(0.75, 0.8, \" Butanol Peak {:>10.3f} \\n Carbon Peak {:>11.3f} \" \\\n",
    "         .format(buta_peak, carb_peak), \\\n",
    "         fontsize=20, bbox=dict(facecolor='none', pad=5.0), transform=plt.gca().transAxes)        \n",
    "\n",
    "#Y-Axis Scaling\n",
    "def adjust_y_axis(x, pos):\n",
    "    return \"{:.0f}\".format(x/10000)\n",
    "plt.gca().yaxis.set_major_formatter(mpl.ticker.FuncFormatter(adjust_y_axis))\n",
    "\n",
    "#Grids\n",
    "plt.axes().xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "plt.axes().yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "plt.grid(b=True, which=\"major\", color=\"gray\", linewidth=1.0, linestyle=\"--\")\n",
    "plt.grid(b=True, which=\"minor\", color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "#lim, ticks, label, legends\n",
    "# plt.xticks(np.arange(-1, 1, 0.1))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(fontsize=25)\n",
    "plt.xlim(-1, 1)\n",
    "plt.xlabel(\"$m^2_{\\pi_0}$ ($GeV^2$)\", fontsize=30)\n",
    "plt.ylabel(\"Counts $(x10^4)$\", fontsize=30)\n",
    "\n",
    "plt.show()\n",
    "# g9a_mmsq_hist_pred.savefig(\"./run_period_1/g9a_mmsq_hist_pred\")\n",
    "# g9a_mmsq_hist_pred.savefig(\"./run_period_2/g9a_mmsq_hist_pred\")\n",
    "# g9a_mmsq_hist_pred.savefig(\"./run_period_3/g9a_mmsq_hist_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Build Model + Prediction (LLapi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Notes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Target Prediction - on Same axes\n",
    "ML_TS_pred   = plt.figure(figsize=(15,15))\n",
    "\n",
    "#Plot\n",
    "n_buta, b_buta, p_buta = plt.hist(df_GMSH[df_GMSH[\"T_pred\"]==0][\"z\"], bins=1000, label=\"Butanol\", alpha=0.7, color=\"#55A868\")\n",
    "n_carb, b_carb, p_carb = plt.hist(df_GMSH[df_GMSH[\"T_pred\"]==1][\"z\"], bins=500, label=\"Carbon\", alpha=0.7, color=\"#C44E52\")\n",
    "\n",
    "#Stats\n",
    "peak_buta = b_buta[np.argmax(n_buta)]\n",
    "mean_buta = df_GMSH[df_GMSH[\"T_pred\"]==0][\"z\"].astype(float).mean()\n",
    "std_buta  = df_GMSH[df_GMSH[\"T_pred\"]==0][\"z\"].astype(float).std()\n",
    "peak_carb = b_carb[np.argmax(n_carb)]\n",
    "mean_carb = df_GMSH[df_GMSH[\"T_pred\"]==1][\"z\"].astype(float).mean()\n",
    "std_carb  = df_GMSH[df_GMSH[\"T_pred\"]==1][\"z\"].astype(float).std()\n",
    "\n",
    "#Texts\n",
    "plt.text(0.05, 0.85, \"Butanol \\n Peak {:>10.3f} \\n $\\mu$ {:>15.3f} \\n $\\sigma$ {:>15.3f}\" \\\n",
    "         .format(peak_buta, mean_buta, std_buta), \\\n",
    "         fontsize=30, bbox=dict(facecolor='none', pad=5.0), transform=plt.gca().transAxes)\n",
    "plt.text(0.05, 0.65, \"Carbon \\n Peak {:>10.3f} \\n $\\mu$ {:>15.3f} \\n $\\sigma$ {:>15.3f}\" \\\n",
    "         .format(peak_carb, mean_carb, std_carb), \\\n",
    "         fontsize=30, bbox=dict(facecolor='none', pad=5.0), transform=plt.gca().transAxes)\n",
    "\n",
    "\n",
    "#Grids\n",
    "plt.axes().xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "plt.axes().yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "plt.grid(b=True, which=\"major\", color=\"gray\", linewidth=1.0, linestyle=\"--\")\n",
    "plt.grid(b=True, which=\"minor\", color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "#Y-Axis Scaling\n",
    "def adjust_y_axis(x, pos):\n",
    "    return \"{:.0f}\".format(x/10000)\n",
    "plt.gca().yaxis.set_major_formatter(mpl.ticker.FuncFormatter(adjust_y_axis))\n",
    "        \n",
    "plt.xlim(-6, 10)\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "plt.xlabel(\"Z-Vertex Position (cm)\", fontsize=30)\n",
    "plt.ylabel(\"Counts $(x10^4)$\", fontsize=30)\n",
    "plt.legend(fontsize=25)\n",
    "plt.show()\n",
    "# ML_TS_pred.savefig(\"ML_TS_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# * Bias term = Fix the offset of the activation funciton to the left or to the right (NOTES)\n",
    "#   $$ activation = sig(w_0*x + w_1*1.0) $$\n",
    "#     * where x = input, bias = 1.0, w_0 = weight of input, w_1 = weight of bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pid', 'E', 'px', 'py', 'pz', 'betac', 'mass', 'betam', 'epho', 'x',\n",
       "       'y', 'z', 'TRIGBITS', 'el_px', 'el_py', 'el_pz', 'el_E', 'timediff',\n",
       "       'runNum', 'p_abs', 'el_p_abs', 'mmsq_pi0', 'el_mmsq_pi0', 'theta',\n",
       "       'phi', 'sector', 'tof_pad', 'beta_diff', 'w', 'cthe_cm', 'tar_Pol',\n",
       "       'tar_Pol_stat', 'tar_Pol_sys', 'tar_Pol_sign', 'bm_helicity', 'pol_pho',\n",
       "       'pol_pho_stat', 'T_fin', 'el_pc_p_abs', 'el_pc_mmsq_pi0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_GMSH.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Change data formats of train_label: 0, 1, 2 -> (0, 0, 1), (0, 1, 0), (1, 0, 0)\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def label_chng(truth):\n",
    "    butanol   = 0\n",
    "    carbon    = 0\n",
    "    polythene = 0\n",
    "    if   (truth == 0):\n",
    "        butanol   = 1\n",
    "    elif (truth == 1):\n",
    "        carbon    = 1\n",
    "    elif (truth == 2):\n",
    "        polythene = 1\n",
    "    return butanol, carbon, polythene\n",
    "    \n",
    "#Vectorize\n",
    "vect_label_chng            = np.vectorize(label_chng, otypes=[np.int, np.int, np.int])\n",
    "butanol, carbon, polythene = vect_label_chng(df_train_label[\"truth\"].values) \n",
    "\n",
    "#Append to df\n",
    "df_train_label[\"butanol\"]    = pd.Series(butanol, index=df_train_label.index)\n",
    "df_train_label[\"carbon\"]     = pd.Series(carbon, index=df_train_label.index)\n",
    "df_train_label[\"polythene\"]  = pd.Series(polythene, index=df_train_label.index)\n",
    "\n",
    "#Drop original \"truth\" column\n",
    "df_train_label.drop(columns=[\"truth\"], inplace=True)\n",
    "\n",
    "#Convert to numpy array\n",
    "train_label = df_train_label.as_matrix() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Parameter Setting\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#learning rate: W(i) = W(i-1) - learning_rate * gradient\n",
    "# learning_rate = 0.1\n",
    "learning_rate = 0.05\n",
    "\n",
    "#number of batches of data to train\n",
    "# num_steps     = 5\n",
    "num_steps     = 500\n",
    "\n",
    "#batch size: Divide training data into batches of ~1000 events (no reason...)\n",
    "# batch_size    = int(len(train_all) / 5)\n",
    "batch_size    = int(len(train_all) / 500)\n",
    "\n",
    "#Display loss scores at every display_step intervals\n",
    "display_step  = 50\n",
    "\n",
    "\n",
    "#14 columns for each event data\n",
    "num_input   = 14\n",
    "#3 classes of results\n",
    "num_classes = 3\n",
    "\n",
    "#number of neurons in 1st and 2nd layers\n",
    "#    -VARY THIS AND SEE HOW IT CHANGES!!!!!!!!!!\n",
    "n_hidden_1  = 14\n",
    "n_hidden_2  = 3\n",
    "\n",
    "#tf Graph input - X=input, Y=output, None means shape not fixed yet (# of rows not fixed)\n",
    "X = tf.placeholder(\"float\", [None, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Layer weight & bias\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "weights = {\"h1\" : tf.Variable(tf.random_normal([num_input, n_hidden_1])), \\\n",
    "           \"h2\" : tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])), \\\n",
    "           \"out\": tf.Variable(tf.random_normal([n_hidden_2, num_classes]))}\n",
    "\n",
    "biases  = {\"b1\" : tf.Variable(tf.random_normal([n_hidden_1])), \\\n",
    "           \"b2\" : tf.Variable(tf.random_normal([n_hidden_2])), \\\n",
    "           \"out\": tf.Variable(tf.random_normal([num_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Create Neural Network fn\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def neural_net(x):\n",
    "    #Hidden fully connected layer with 14 neurons\n",
    "    #    -multiple input (x) by weights ([num_input, n_hidden_1])\n",
    "    #    -Add first biase[\"b1\"] to center it\n",
    "    layer_1   = tf.add(tf.matmul(x, weights[\"h1\"]), biases[\"b1\"])\n",
    "    \n",
    "    #Relu activation \n",
    "    relu_1    = tf.nn.relu(layer_1)\n",
    "    \n",
    "    #Hidden fully connected layer with 14 neurons\n",
    "    layer_2   = tf.add(tf.matmul(relu_1, weights[\"h2\"]), biases[\"b2\"])    \n",
    "\n",
    "    #Output fully connected layer with a neuron (node) for each class\n",
    "    out_layer = tf.nn.softmax(tf.matmul(layer_2, weights[\"out\"]) + biases[\"out\"])\n",
    "    \n",
    "    #return final layer output in same dim as input\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Compile model - optimizer + loss fn\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Construct model\n",
    "#    -logits = unscaled log probabilityes -> results from output layer\n",
    "logits          = neural_net(X)\n",
    "\n",
    "#Loss function\n",
    "#    -reduce_mean() computes mean across dimenstions of tensor\n",
    "#    -logits        = Unscaled log probabilities\n",
    "#    -cross_entropy = inv. proportional to probability - Computes cross entropy of `logits` and `labels`\n",
    "#    -softmax       = returns array of prob. scores that sum to 1 - IOW, normalized\n",
    "loss_op         = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "\n",
    "#Optmizer\n",
    "optimizer       = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "#Train Operator = optimizer to minimize loss function output\n",
    "train_op        = optimizer.minimize(loss_op)\n",
    "\n",
    "#Evaluate model\n",
    "#    -with test logits, for dropout to be disabled\n",
    "#    -tf.argmax(logits, 1) = highest value in logits (vector) values\n",
    "#    -tf.argmax(Y, 1) = highest values in Y (output)\n",
    "#    -tf.equal() = returns truth results \n",
    "#    -tf.cast() = casts a tensor to a new type, not altering dimesions of the tensor\n",
    "correct_pred    = tf.equal(tf.argmax(logits, 1), tf.argmax(Y,1)) \n",
    "accuracy_op     = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#Initializa the variables (assign default values)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    #Run the initializer to initialize variables to defaults\n",
    "    sess.run(init)\n",
    "    \n",
    "    #prediction_before = sess.run(logits, feed_dict={X:test_all})\n",
    "    #print(\"logits on testdata: \\n\", prediction_before)\n",
    "\n",
    "    for step in range(0, num_steps):\n",
    "        #loop over batches of data\n",
    "        #    -batch_x = (batch_size, num_input)\n",
    "        #    -batch_y = (batch_size, num_classes)\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for i in range(0, batch_size):\n",
    "            batch_x.append(train_all[i + step*batch_size])\n",
    "            batch_y.append(train_label[i + step*batch_size])\n",
    "        batch_x = np.asarray(batch_x)\n",
    "        batch_y = np.asarray(batch_y)\n",
    "        \n",
    "        #Run optimization operation (backprop)\n",
    "        #    -X goes into logits = neural_net(X), which is the starting input values\n",
    "        #    -Y goes into loss_op, which are labels (truth values?)\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y:batch_y})\n",
    "        \n",
    "        #Show status\n",
    "        if (step % display_step == 0 or step == 0 or step ==num_steps-1):\n",
    "            #Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy_op], feed_dict={X:batch_x, Y:batch_y}) \n",
    "            print(\"Step \" + str(step) + \\\n",
    "                  \", \\t\\t Minibatch Loss = {:.4f}\".format(loss) + \\\n",
    "                  \", \\t\\t Training Accuracy = {:.3f}\".format(acc))\n",
    "    print(\"Optimization Finished!\") \n",
    "\n",
    "    #Calculate accuracy for MNIST test images\n",
    "    #    -My test data does not have ground truth values. Just make the predictions and append\n",
    "    #print(\"#-------------------------------------------------------------------------------------\")\n",
    "    #print(\"Testing Accuracy: \", sess.run(accuracy_op, feed_dict={X:test_all, Y:mnist.test_label}))\n",
    "    \n",
    "    \n",
    "#Predictions on test data - has to be done within same session()\n",
    "#------------------------------------------------------------------------------------------------------\n",
    "    prediction = sess.run(logits, feed_dict={X:test_all})\n",
    "    print(\"logits on testdata: \\n\", prediction)\n",
    "    \n",
    "    \n",
    "    print(sess.run(weights[\"h1\"]))  \n",
    "    print(sess.run(weights[\"h1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#predictions_list is a list of final predictions of target on test_all data\n",
    "predictions_list = []\n",
    "for i in range(0, len(prediction)):\n",
    "    predictions_list.append(np.argmax(prediction[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Append prediction to df\n",
    "df_GMSH[\"T_ll_pred\"] = pd.Series(predictions_list, index=df_GMSH.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Target Prediction\n",
    "g9a_hit_pos_yz_hist_pred_sep, [ax1, ax2, ax3] = plt.subplots(3, 1, figsize=(15,15))\n",
    "\n",
    "#target label\n",
    "target_label = df_GMSH.T_ll_pred.unique()\n",
    "\n",
    "#Grids\n",
    "for i in [ax1, ax2, ax3]:\n",
    "    i.axes.xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    i.axes.yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    i.grid(b=True, which=\"major\", color=\"w\", linewidth=1.0)\n",
    "    i.grid(b=True, which=\"minor\", color=\"w\", linewidth=0.5)\n",
    "\n",
    "for i in target_label:\n",
    "    hit = df_GMSH[df_GMSH.T_ll_pred == i]\n",
    "    if i == 0:\n",
    "        target = \"Butanol\"\n",
    "        ax1.hist(hit.z, alpha=0.5, bins=500, histtype='bar', label=target) \n",
    "    elif i== 1:\n",
    "        target = \"Carbon\"\n",
    "        ax2.hist(hit.z, alpha=0.5, bins=500, histtype='bar', label=target) \n",
    "    elif i==2:\n",
    "        target = \"Polythene\"\n",
    "        ax3.hist(hit.z, alpha=0.5, bins=500, histtype='bar', label=target) \n",
    "                        \n",
    "ax1.set_title(\"Butanol\")\n",
    "ax2.set_title(\"Carbon\")\n",
    "ax3.set_title(\"Polythene\")\n",
    "ax1.set_xlim(-10, 20)\n",
    "ax2.set_xlim(-10, 20)\n",
    "ax3.set_xlim(-10, 20)\n",
    "plt.xlabel(\"Z-Vertex Position (cm)\")\n",
    "# plt.xlim(-10,20)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "# g9a_hit_pos_yz_hist_pred_sep.savefig(\"g9a_hit_pos_yz_hist_pred_sep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydrogen Contamination "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Training Data (MUST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Notes for Ice training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "* Possible training events for ICE (NOTES)\n",
    " 1. Tight cut on the mmsq_pi0 sharp peak on the g9a Carbon data + events with z-vertex > 7cm.\n",
    "     * `Since ice was reported to have been form on the right side of the Carbon target. [Steffen Strauch's Analysis page of FROST wiki]` \n",
    "     * Since bound-nucleon events with Fermi momentum will contribute the mmsq peak to be broad and the free-nucleon\n",
    "      events will have sharper mmsq peak.\n",
    "    * Selecting sharper peak reduces background (carbon) - __there is no perfectly pure free-nucleon training data__.\n",
    "      1. Create a df from events that are labeled as Carbon fron the _Target Selection_ section.\n",
    "      2. Make a mmsq_pi0 plot from these events, select events that fall in the sharp peak. Use them as ICE \n",
    "        * Calculate BIN WIDTH $\\rightarrow$ sharp peak position $\\pm$ BIN WIDTH / 2 $\\rightarrow$ ice training data!\n",
    "  2. MC simulated free-nucleon events that will correspond to the sharp peak on the Carbon or Butanol\n",
    "  \n",
    "  \n",
    "* 2 possible training events for Carbon\n",
    "  1. Use g9b Carbon data as the bound-nucleaon traianing events \n",
    "    * Only single-tracked PROTONS only! Otherwise, mmsq is too messed up and the NN model will fail\n",
    "  2. Use the very negative portion of mmsq_pi0 as the bound-nucleon training events.\n",
    "    * Very positive region of mmsq_pi0 is not good since there are multi-pion events where only the protons are\n",
    "      detected.\n",
    "    * Concerned that selecting only negative mmsq_pi0 would lead to biased training\n",
    "      * Just don't use mmsq_pi0 as classifying parameter then!\n",
    "      * Select out events that have very negative mmsq_pi0, see there distribution in yz hit positions\n",
    "        * If they are dispersed well throughout the left side of the carbon, then we can use these events as\n",
    "          training events for bound-nucleon events\n",
    "          \n",
    "* `Study training data size dependence predictions`\n",
    "* `Study # of epochs dependence on predictions`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Notes for Carbon training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "source": [
    "(NOTES)\n",
    "* if peak for mmsq_pi0 is broader, they are from bound-nucleon events (carbon) due to Fermi momentum\n",
    "* If the events' z-vertex is in [5.5, 6.5] , then they are certainly from carbon, since ice was reported to have been formed on the right side region of carbon target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Code for Ice training (MUST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Predicted Carbon (MUST)\n",
    "df_carbon_pred = df_GMSH[df_GMSH[\"T_pred\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Carbon predicted (CHECK)\n",
    "g9a_yz_carbon_pred = plt.figure(figsize=(15,15))\n",
    "ax                 = plt.axes()\n",
    "n, b, p = ax.hist(df_carbon_pred.z, bins=500, alpha=0.6, histtype='bar', label=\"carbon\")\n",
    "for i in range(0, int(len(p))):\n",
    "    if b[i] >= 5.0 and b[i] <= 7.0:\n",
    "        p[i].set_facecolor('r')\n",
    "\n",
    "#Grids\n",
    "plt.axes().xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.axes().yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.grid(b=True, which=\"major\", color=\"w\", linewidth=1.0)\n",
    "plt.grid(b=True, which=\"minor\", color=\"w\", linewidth=0.5)\n",
    "\n",
    "plt.xlim(2, 10)\n",
    "plt.axvline(x=7.0, linestyle = '--')\n",
    "plt.axvline(x=5.0, linestyle = '--')\n",
    "# plt.legend()\n",
    "plt.xlabel(\"Z-Vertex Position (cm)\")\n",
    "plt.title(\"Predicted Carbon Events\")\n",
    "# plt.text(8.0, 100, \"{:10}{:3}{:.4f} GeV\\n{:20}{:3}{:.4f} GeV\"\\\n",
    "#                     .format('Peak', \" = \", 0.0245, \"$\\sigma$\", \" = \", df_carbon_pred.z.std())) \n",
    "plt.show()\n",
    "# g9a_yz_carbon_pred.savefig(\"g9a_yz_carbon_pred\")\n",
    "\n",
    "bin_max = np.argmax(n)\n",
    "print(\"b[bin_max]: \", b[bin_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Ice selection from Carbon data (MUST)\n",
    "g9a_mmsq_pi0_carbon_pred = plt.figure(figsize=(15,15))\n",
    "ax                       = plt.axes()\n",
    "n, b, p = ax.hist(df_carbon_pred.mmsq_pi0, bins=1000, alpha=0.8, histtype='bar', color=\"#4C72B0\")\n",
    "\n",
    "#stats\n",
    "bin_max     = np.argmax(n)\n",
    "ice_up_lim  = b[bin_max] + df_carbon_pred[\"mmsq_pi0\"].astype(float).std()/10\n",
    "ice_low_lim = b[bin_max] - df_carbon_pred[\"mmsq_pi0\"].astype(float).std()/10\n",
    "\n",
    "#Color specific patches\n",
    "for i in range(0, int(len(p))):\n",
    "    if b[i] >= ice_low_lim and b[i] <= ice_up_lim:\n",
    "        p[i].set_facecolor('#C44E52')\n",
    "        \n",
    "#Custom Legend        \n",
    "custom_label = [mpl.patches.Patch(facecolor=\"#C44E52\", alpha=0.8, label=\"ice train\"), \\\n",
    "                mpl.patches.Patch(facecolor=\"#4C72B0\", alpha=0.8, label=\"carbon\")]\n",
    "plt.legend(handles=custom_label, fontsize=30)\n",
    "\n",
    "#axvlines\n",
    "plt.axvline(ice_low_lim, linestyle=\"--\")\n",
    "plt.axvline(ice_up_lim, linestyle=\"--\")    \n",
    "        \n",
    "#Grids\n",
    "plt.axes().xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.axes().yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.grid(b=True, which=\"major\", color=\"gray\", linewidth=1.0, linestyle=\"--\")\n",
    "plt.grid(b=True, which=\"minor\", color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "#Y-Axis Scaling\n",
    "def adjust_y_axis(x, pos):\n",
    "    return \"{:.0f}\".format(x/100)\n",
    "plt.gca().yaxis.set_major_formatter(mpl.ticker.FuncFormatter(adjust_y_axis))\n",
    "\n",
    "#ranges\n",
    "plt.xlim(-1, 1)\n",
    "\n",
    "#labels, ticks\n",
    "plt.xlabel(\"$m^2_{\\pi_0}$ ($GeV^2$)\", fontsize=30)\n",
    "plt.ylabel(\"Counts $(x10^2)$\", fontsize=30)\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "\n",
    "#Texts\n",
    "plt.text(0.75, 0.78, \" Peak {:>10.3f} \\n $\\sigma$ {:>15.3f}\".format(b[bin_max], df_carbon_pred.astype(float).mmsq_pi0.std()), \\\n",
    "         fontsize=30, transform=plt.gca().transAxes, bbox=dict(facecolor='none', pad=5.0)) \n",
    "\n",
    "\n",
    "plt.show()\n",
    "# g9a_mmsq_pi0_carbon_pred.savefig(\"g9a_mmsq_pi0_carbon_pred\")\n",
    "\n",
    "print(\"Mode: \", b[bin_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Ice train 1 (MUST)\n",
    "df_ice_train = df_carbon_pred[(df_carbon_pred[\"mmsq_pi0\"] >= ice_low_lim) & \\\n",
    "                              (df_carbon_pred[\"mmsq_pi0\"] <= ice_up_lim)  & \\\n",
    "                              ((df_carbon_pred[\"z\"] >= 6.) & (df_carbon_pred[\"z\"] <= 7.5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Evidence of ice from Stenffen (CHECK)\n",
    "Image(filename=\"ice_evidence_Steffen_2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Code  for Carbon training (MUST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#hitpos_x_maxbin, hitpos_y_maxbin (MUST)\n",
    "hitpos_x_maxbin = plt.figure(figsize=(12, 6))\n",
    "n, b_x, p = plt.hist(df_GMSH[\"x\"], bins=200, range=[-1.5, 1.5])\n",
    "\n",
    "#stats\n",
    "n_max_x = np.argmax(n)\n",
    "plt.axvline(b_x[n_max_x], linestyle=\"--\", color=\"#8C0900\")\n",
    "plt.text(0.8, 0.8, \"Max bin = {:.3f}\".format(b_x[n_max_x]), fontsize=15, bbox={\"facecolor\":\"none\", \"pad\":5.0}, \\\n",
    "         transform=plt.gca().transAxes)\n",
    "\n",
    "\n",
    "plt.xlabel(\"x (cm)\", fontsize=20)\n",
    "plt.show()\n",
    "#==========================================================================================================================\n",
    "\n",
    "hitpos_y_maxbin = plt.figure(figsize=(12, 6))\n",
    "n, b_y, p = plt.hist(df_GMSH[\"y\"], bins=200, range=[-1.5, 1.5])\n",
    "\n",
    "#stats\n",
    "n_max_y = np.argmax(n)\n",
    "plt.axvline(b_y[n_max_y], linestyle=\"--\", color=\"#8C0900\")\n",
    "plt.text(0.8, 0.8, \"Max bin = {:.3f}\".format(b_y[n_max_y]), fontsize=15, bbox={\"facecolor\":\"none\", \"pad\":5.0}, \\\n",
    "         transform=plt.gca().transAxes)\n",
    "\n",
    "plt.xlabel(\"y (cm)\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "x_center = round(b_x[n_max_x],4)\n",
    "y_center = round(b_y[n_max_y],4)\n",
    "\n",
    "print(\"x_center = \", x_center)\n",
    "print(\"y_center = \", y_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Carbon Training Data (MUST)\n",
    "#    -x_center, y_center computed in He-bath selection \n",
    "\n",
    "df_carbon_train = df_carbon_pred[((df_carbon_pred[\"mmsq_pi0\"] <= ice_low_lim)  | \\\n",
    "                                 (df_carbon_pred[\"mmsq_pi0\"] >= ice_up_lim))   & \\\n",
    "                                 ((df_carbon_pred[\"z\"] <= 6.76) & (df_carbon_pred[\"z\"] >= 5.54)) & \\\n",
    "                                 ((pow(df_carbon_pred[\"x\"] - (x_center), 2) + pow(df_carbon_pred[\"y\"] - (y_center), 2)) < 0.8**2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Carbon training (CHECK)\n",
    "carbon_training, ax = plt.subplots(2, 1, figsize=(15, 15))\n",
    "\n",
    "ax[0].hist(df_carbon_train[\"mmsq_pi0\"], bins=500, range=[-1, 1])\n",
    "ax[1].hist(df_carbon_train[\"z\"], bins=512, range=(5, 7))\n",
    "\n",
    "#grids\n",
    "for i in ax:\n",
    "    i.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    i.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "    i.grid(b=True, which=\"major\", color=\"w\", linewidth=1.0)\n",
    "    i.grid(b=True, which=\"minor\", color=\"w\", linewidth=0.4)\n",
    "    \n",
    "#ticks change fontsize\n",
    "for i in ax:\n",
    "    i.tick_params(labelsize=15) \n",
    "\n",
    "ax[0].set_xlabel(\"$m^2_{\\pi_0}$ ($GeV^2$)\", fontsize=30)    \n",
    "ax[0].set_ylabel(\"Counts\", fontsize=30)    \n",
    "ax[1].set_xlabel(\"$z-vertex$ ($cm$)\", fontsize=30)    \n",
    "ax[1].set_ylabel(\"Counts\", fontsize=30)    \n",
    "    \n",
    "plt.show()\n",
    "# carbon_training.savefig(\"carbon_train_hydrocon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#FROST target layout (CHECK)\n",
    "Image(filename=\"frost_target_position.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Finding adequate size of training dataset for Ice and Carbon (MUST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of total ICE training events (before random selection)    =  3672\n",
      "# of total CARBON training events (before random selection) =  101434\n",
      "# of ICE training events (value chosen)          =  2500\n",
      "# of carbon training events to randomly select   =  207177\n"
     ]
    }
   ],
   "source": [
    "num_ice_train  = 2500\n",
    "num_carb_train = int((len(df_carbon_train) / len(df_ice_train)) * num_ice_train)*3\n",
    "\n",
    "print(\"# of total ICE training events (before random selection)    = \", len(df_ice_train))\n",
    "print(\"# of total CARBON training events (before random selection) = \", len(df_carbon_train))\n",
    "\n",
    "print(\"# of ICE training events (value chosen)          = \", num_ice_train)\n",
    "print(\"# of carbon training events to randomly select   = \", num_carb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Select Random points for reduced training data\n",
    "df_ice_train   = df_ice_train.sample(num_ice_train)\n",
    "\n",
    "#Select Random points for reduced training data\n",
    "df_carbon_train   = df_carbon_train.sample(num_carb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#When training data too low\n",
    "\n",
    "#Select Random points for reduced training data\n",
    "df_ice_train   = df_ice_train.sample(num_ice_train, replace=True)\n",
    "\n",
    "#Select Random points for reduced training data\n",
    "df_carbon_train   = df_carbon_train.sample(num_carb_train, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Training Data Finalize (MUST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Ground Truth column - train labels\n",
    "df_ice_train[\"truth\"]    = 0\n",
    "df_carbon_train[\"truth\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Columns list\n",
    "df_ice_train_col    = df_ice_train.columns.tolist()\n",
    "\n",
    "#Align the column order\n",
    "df_carbon_train     = df_carbon_train[df_ice_train_col]\n",
    "df_carbon_train_col = df_carbon_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Combine trainig data of ice + carbom\n",
    "df_train_all = pd.concat([df_ice_train, df_carbon_train])\n",
    "\n",
    "#Separate df for ground truth - train label\n",
    "df_train_label = pd.DataFrame(df_train_all[\"truth\"])\n",
    "\n",
    "#Drop groun truth column in training data\n",
    "df_train_all.drop(columns=[\"truth\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pid', 'E', 'px', 'py', 'pz', 'betac', 'mass', 'betam', 'epho', 'x',\n",
       "       'y', 'z', 'scPdHt', 'TRIGBITS', 'el_px', 'el_py', 'el_pz', 'el_E',\n",
       "       'timediff', 'runNum', 'p_abs', 'el_p_abs', 'mmsq_pi0', 'el_mmsq_pi0',\n",
       "       'theta', 'phi', 'sector', 'tof_pad', 'beta_diff', 'phi_sec',\n",
       "       'el_pc_p_abs', 'el_pc_pz', 'el_pc_mmsq_pi0', 'w', 'beta_cm', 'gamma_cm',\n",
       "       'pz_cm', 'p_cm_abs', 'theta_cm', 'cthe_cm', 'tar_Pol', 'tar_Pol_stat',\n",
       "       'tar_Pol_sys', 'tar_Pol_sign', 'bm_helicity', 'pol_pho', 'pol_pho_stat',\n",
       "       'T_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#drop the columns that df_train_all dropped already\n",
    "\n",
    "df_train_all = df_train_all.drop(columns=['pid', 'E', 'px', 'py', 'pz', 'betac', 'mass', 'betam', 'scPdHt', 'TRIGBITS',\n",
    "                                           'timediff', 'runNum', 'p_abs', 'mmsq_pi0',\n",
    "                                           'sector', 'tof_pad', 'beta_diff', 'w', 'beta_cm',\n",
    "                                           'gamma_cm', 'pz_cm', 'p_cm_abs', 'theta_cm', 'cthe_cm', 'tar_Pol',\n",
    "                                           'tar_Pol_stat', 'tar_Pol_sys', 'tar_Pol_sign', 'bm_helicity', 'pol_pho',\n",
    "                                           'pol_pho_stat', \"T_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Drop when doing 2nd time\n",
    "# df_train_all.drop(columns=[\"ice_pred\", \"T_fin\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Convert to numpy ndarray \n",
    "train_all   = df_train_all.values\n",
    "train_label = df_train_label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209677\n",
      "209677\n",
      "(209677, 16)\n",
      "(209677, 1)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_all))\n",
    "print(len(train_label))\n",
    "print(train_all.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Test Data (MUST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#drop the columns that df_train_all dropped already\n",
    "df_GMSH_ml = df_GMSH.drop(columns=['pid', 'E', 'px', 'py', 'pz', 'betac', 'mass', 'betam', 'scPdHt', 'TRIGBITS',\n",
    "                                   'timediff', 'runNum', 'p_abs', 'mmsq_pi0',\n",
    "                                   'sector', 'tof_pad', 'beta_diff', 'w', 'beta_cm',\n",
    "                                   'gamma_cm', 'pz_cm', 'p_cm_abs', 'theta_cm', 'cthe_cm', 'tar_Pol',\n",
    "                                   'tar_Pol_stat', 'tar_Pol_sys', 'tar_Pol_sign', 'bm_helicity', 'pol_pho',\n",
    "                                   'pol_pho_stat', \"T_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Drop when doing 2nd time\n",
    "# df_train_all.drop(columns=[\"ice_pred\", \"T_fin\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['epho', 'x', 'y', 'z', 'el_px', 'el_py', 'el_pz', 'el_E', 'el_p_abs', 'el_mmsq_pi0', 'theta', 'phi', 'phi_sec', 'el_pc_p_abs', 'el_pc_pz', 'el_pc_mmsq_pi0']\n",
      "['epho', 'x', 'y', 'z', 'el_px', 'el_py', 'el_pz', 'el_E', 'el_p_abs', 'el_mmsq_pi0', 'theta', 'phi', 'phi_sec', 'el_pc_p_abs', 'el_pc_pz', 'el_pc_mmsq_pi0']\n"
     ]
    }
   ],
   "source": [
    "#Change order of columns so that columns of training data and test data matchesÂ¶\n",
    "df_train_all_cols = df_train_all.columns.tolist()\n",
    "df_GMSH_ml = df_GMSH_ml[df_train_all_cols]\n",
    "\n",
    "print(df_train_all_cols)\n",
    "print(df_GMSH_ml.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#convert df_GPID_MVRT to numpy ndarry\n",
    "test_all = df_GMSH_ml.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Summary of training + test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "So far we have the following data sets:\n",
    "* test_all = test data set \n",
    "  * df_GMSH_ml\n",
    "* train_all = training data set\n",
    "  * df_train_all \n",
    "* train_label  = trainig label (true values)\n",
    "  * df_train_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Model + Prediction (keras) (MUST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer Setup\n",
    "model_ice = keras.Sequential()\n",
    "model_ice.add(keras.layers.Dense(15, activation=tf.nn.relu))\n",
    "model_ice.add(keras.layers.Dense(15, activation=tf.nn.relu))\n",
    "# model_ice.add(keras.layers.Dense(15, activation=tf.nn.relu))\n",
    "# model_ice.add(keras.layers.Dense(15, activation=tf.nn.relu))\n",
    "model_ice.add(keras.layers.Dense(2, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile: Optimizer + Loss function\n",
    "model_ice.compile(optimizer  = tf.optimizers.Adam(),\n",
    "                    loss     = 'sparse_categorical_crossentropy',\n",
    "                    metrics  = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "model_ice.fit(train_all, train_label, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "predictions_ice = model_ice.predict(test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_ice\n",
    "predictions_list = []\n",
    "for i in range(0, len(predictions_ice)):\n",
    "    predictions_list.append(np.argmax(predictions_ice[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append predicted values (predictions_list) to df\n",
    "df_GMSH[\"ice_pred\"] = pd.Series(predictions_list, index=df_GMSH.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Target selection final output into df_GHSM (MUST)\n",
    "#    -Oprimized Version - np.vertorize()\n",
    "def T_fin(T_pred, ice_pred):\n",
    "    tfin = 0\n",
    "    #Butanol\n",
    "    if  (T_pred == 0):\n",
    "        tfin = 0\n",
    "    #Ice\n",
    "    elif(T_pred == 1 and ice_pred == 0):\n",
    "        tfin = 3\n",
    "    #Carbon\n",
    "    elif(T_pred == 1 and ice_pred == 1):\n",
    "        tfin = 1\n",
    "    #Polythene\n",
    "    elif(T_pred == 2):\n",
    "        tfin = 2\n",
    "    return tfin\n",
    "    \n",
    "#Vectorize\n",
    "vect_T_fin             = np.vectorize(T_fin, otypes=[np.int])\n",
    "T_fin                  = vect_T_fin(df_GMSH[\"T_pred\"].values, df_GMSH[\"ice_pred\"].values)\n",
    "\n",
    "#Append to df\n",
    "df_GMSH[\"T_fin\"] = pd.Series(T_fin, index=df_GMSH.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#final predictions plot (CHECK)\n",
    "g9a_final_target_pred_all = plt.figure(figsize=(12,12))\n",
    "target_label = df_GMSH.T_fin.unique()\n",
    "ax=plt.axes()\n",
    "\n",
    "for i in target_label:\n",
    "    hit = df_GMSH[df_GMSH.T_fin == i]\n",
    "    if   i == 0:\n",
    "        target = \"butanol\"\n",
    "        n_buta, b_buta, p_buta = ax.hist(hit.z, alpha=0.5, bins=600, label=target) \n",
    "    elif i== 1:\n",
    "        target = \"Carbon\"\n",
    "        n_carb, b_carb, p_carb = ax.hist(hit.z, alpha=0.5, bins=500, label=target) \n",
    "    elif i== 2:\n",
    "        target = \"polythene\"\n",
    "        n_poly, b_poly, p_poly = ax.hist(hit.z, alpha=0.5, bins=500, label=target) \n",
    "    elif i== 3:\n",
    "        target = \"ice\"\n",
    "        n_ice, b_ice, p_ice = ax.hist(hit.z, alpha=0.5, bins=500, label=target) \n",
    "\n",
    "#Grids\n",
    "plt.axes().xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.axes().yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.grid(b=True, which=\"major\", color=\"w\", linewidth=1.0)\n",
    "plt.grid(b=True, which=\"minor\", color=\"w\", linewidth=0.5)\n",
    "        \n",
    "plt.xlim(-5,20)\n",
    "plt.xlabel(\"Z-Vertex Position (cm)\", fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "# plt.title(\"\", fontsize=15)\n",
    "plt.show()\n",
    "# g9a_final_target_pred_all.savefig(\"./run_period_2/g9a_final_target_pred_all\")\n",
    "# g9a_final_target_pred_all.savefig(\"./run_period_3/g9a_final_target_pred_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Final predictions Z-Vertex - only for carbon and ice (CHECK)\n",
    "g9a_final_target_pred_ca_ice = plt.figure(figsize=(12,12))\n",
    "target_label = df_GMSH.T_fin.unique()\n",
    "ax=plt.axes()\n",
    "\n",
    "for i in target_label:\n",
    "    hit = df_GMSH[df_GMSH.T_fin == i]\n",
    "#     if   i == 0:\n",
    "#         target = \"butanol\"\n",
    "#         ax.hist(hit.z, alpha=0.5, bins=1000, label=target) \n",
    "    if i== 1:\n",
    "        target = \"carbon\"\n",
    "        n_carb, b_carb, p_carb = ax.hist(hit.z, alpha=0.5, bins=300, label=target) \n",
    "#     elif i== 2:\n",
    "#         target = \"polythene\"\n",
    "#         ax.hist(hit.z, alpha=0.5, bins=1000, label=target) \n",
    "    elif i== 3:\n",
    "        target = \"ice\"\n",
    "        n_ice, b_ice, p_ice = ax.hist(hit.z, alpha=0.5, bins=b_carb, label=target) \n",
    "\n",
    "#Grids\n",
    "plt.axes().xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.axes().yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.grid(b=True, which=\"major\", color=\"grey\", linewidth=1.0)\n",
    "plt.grid(b=True, which=\"minor\", color=\"grey\", linewidth=0.5)\n",
    "        \n",
    "plt.xlim(2,12)\n",
    "plt.xlabel(\"Z-Vertex Position (cm)\", fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "# plt.title(\"\", fontsize=15)\n",
    "plt.show()\n",
    "# g9a_final_target_pred_ca_ice.savefig(\"./run_period_2/g9a_final_target_pred_ca_ice\")\n",
    "# g9a_final_target_pred_ca_ice.savefig(\"./run_period_3/g9a_final_target_pred_ca_ice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Final predictions MMSQ -  only for carbon and ice (CHECK)\n",
    "g9a_final_target_pred_ca_ice_mmsq = plt.figure(figsize=(12,12))\n",
    "target_label = df_GMSH.T_fin.unique()\n",
    "ax=plt.axes()\n",
    "\n",
    "for i in target_label:\n",
    "    hit = df_GMSH[df_GMSH.T_fin == i]\n",
    "#     if   i == 0:\n",
    "#         target = \"butanol\"\n",
    "#         ax.hist(hit.z, alpha=0.5, bins=1000, label=target) \n",
    "    if i== 1:\n",
    "        target = \"carbon\"\n",
    "        ax.hist(hit.mmsq_pi0, alpha=0.5, bins=500, label=target, color=\"#4C72B0\") \n",
    "#     elif i== 2:\n",
    "#         target = \"polythene\"\n",
    "#         ax.hist(hit.z, alpha=0.5, bins=1000, label=target) \n",
    "    elif i== 3:\n",
    "        target = \"ice\"\n",
    "        ax.hist(hit.mmsq_pi0, alpha=0.5, bins=500, label=target, color=\"#C44E52\") \n",
    "\n",
    "#Grids\n",
    "plt.axes().xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.axes().yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.grid(b=True, which=\"major\", color=\"w\", linewidth=1.0)\n",
    "plt.grid(b=True, which=\"minor\", color=\"w\", linewidth=0.5)\n",
    "        \n",
    "plt.xlim(-2,1)\n",
    "plt.xlabel(\"$m^2_{\\pi_0}$ ($GeV^2$)\", fontsize=15)\n",
    "plt.legend(fontsize=15)\n",
    "# plt.title(\"\", fontsize=15)\n",
    "plt.show()\n",
    "# g9a_final_target_pred_ca_ice_mmsq.savefig(\"./run_period_2/g9a_final_target_pred_ca_ice_mmsq\")\n",
    "# g9a_final_target_pred_ca_ice_mmsq.savefig(\"./run_period_3/g9a_final_target_pred_ca_ice_mmsq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#g9a_final_target_pred_ca_ice_mmsq_zvert (CHECK)\n",
    "g9a_final_target_pred_ca_ice_mmsq_zvert, subplots = plt.subplots(3, 1, figsize=(20, 20)) \n",
    "\n",
    "a = subplots[0].hist2d(df_GMSH[\"z\"][(df_GMSH[\"T_fin\"] == 1) | (df_GMSH[\"T_fin\"] == 3)], \n",
    "                       df_GMSH[\"mmsq_pi0\"][(df_GMSH[\"T_fin\"] == 1) | (df_GMSH[\"T_fin\"] == 3)], \n",
    "                       cmap=\"jet\", cmin=0, bins=300, range=[[4, 8], [-1.0, 1.0]], norm=mpl.colors.LogNorm())\n",
    "\n",
    "b = subplots[1].hist2d(df_GMSH[\"z\"][(df_GMSH[\"T_fin\"] == 1)], df_GMSH[\"mmsq_pi0\"][(df_GMSH[\"T_fin\"] == 1)],\n",
    "                       cmap=\"jet\", cmin=0, bins=300, range=[[4, 8], [-1.0, 1.0]], norm=mpl.colors.LogNorm())\n",
    "\n",
    "c = subplots[2].hist2d(df_GMSH[\"z\"][(df_GMSH[\"T_fin\"] == 3)], df_GMSH[\"mmsq_pi0\"][(df_GMSH[\"T_fin\"] == 3)],\n",
    "                       cmap=\"jet\", cmin=0, bins=300, range=[[4, 8], [-1.0, 1.0]], norm=mpl.colors.LogNorm())\n",
    "\n",
    "\n",
    "#Add axes\n",
    "cbaxes_0 = g9a_final_target_pred_ca_ice_mmsq_zvert.add_axes([0.91, 0.125, 0.03, 0.756])   # x_pos, y_pos, width, length\n",
    "\n",
    "#Set Colorbar ([3] indicated the subplot)\n",
    "cbar = g9a_final_target_pred_ca_ice_mmsq_zvert.colorbar(a[3], cax=cbaxes_0)\n",
    "\n",
    "#Set Colorbar limit\n",
    "# a[3].set_clim(0, 100)\n",
    "# b[3].set_clim(0, 100)\n",
    "# c[3].set_clim(0, 100)\n",
    "\n",
    "#Change Color Bar fontsize\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "#X and Y labels\n",
    "# subplots[0].set_xlabel(\"Z-Vertex (cm)\", fontsize=25)\n",
    "# subplots[1].set_xlabel(\"Z-Vertex (cm)\", fontsize=25)\n",
    "subplots[2].set_xlabel(\"Z-Vertex (cm)\", fontsize=40)\n",
    "subplots[0].set_ylabel(\"$m^2_{\\pi_0}$ $(GeV^2)$\", fontsize=30)\n",
    "subplots[1].set_ylabel(\"$m^2_{\\pi_0}$ $(GeV^2)$\", fontsize=30)\n",
    "subplots[2].set_ylabel(\"$m^2_{\\pi_0}$ $(GeV^2)$\", fontsize=30)\n",
    "\n",
    "#Ticks\n",
    "subplots[0].tick_params(labelsize=25)\n",
    "subplots[1].tick_params(labelsize=25)\n",
    "subplots[2].tick_params(labelsize=25)\n",
    "\n",
    "#Layout change\n",
    "# age_IPSYN_all.tight_layout()\n",
    "\n",
    "#Title\n",
    "subplots[0].set_title(\"Carbon + Ice\", fontsize=35)\n",
    "subplots[1].set_title(\"Carbon\", fontsize=35)\n",
    "subplots[2].set_title(\"Ice\", fontsize=35)\n",
    "\n",
    "#Spacing\n",
    "g9a_final_target_pred_ca_ice_mmsq_zvert.subplots_adjust(hspace=0.35)\n",
    "\n",
    "plt.show()\n",
    "# g9a_final_target_pred_ca_ice_mmsq_zvert.savefig(\"./run_period_1//g9a_final_target_pred_ca_ice_mmsq_zvert\")\n",
    "# g9a_final_target_pred_ca_ice_mmsq_zvert.savefig(\"./run_period_2/g9a_final_target_pred_ca_ice_mmsq_zvert\")\n",
    "# g9a_final_target_pred_ca_ice_mmsq_zvert.savefig(\"./run_period_3//g9a_final_target_pred_ca_ice_mmsq_zvert\")\n",
    "# g9a_final_target_pred_ca_ice_mmsq_zvert.savefig(\"./run_period_4_1//g9a_final_target_pred_ca_ice_mmsq_zvert\")\n",
    "# g9a_final_target_pred_ca_ice_mmsq_zvert.savefig(\"./run_period_5_1//g9a_final_target_pred_ca_ice_mmsq_zvert\")\n",
    "# g9a_final_target_pred_ca_ice_mmsq_zvert.savefig(\"./run_period_6_1//g9a_final_target_pred_ca_ice_mmsq_zvert\")\n",
    "# g9a_final_target_pred_ca_ice_mmsq_zvert.savefig(\"./run_period_7_1//g9a_final_target_pred_ca_ice_mmsq_zvert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Butanol vs Carbon - ice mmsp (CHECK)\n",
    "g9a_mmsq_pred_ml = plt.figure(figsize=(15,15))\n",
    "\n",
    "#Plot\n",
    "n_buta, b_buta, p_buta = plt.hist(df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==0], alpha=1, bins=\"fd\", histtype='step', label=\"butanol\", linewidth=2) \n",
    "bin_max_buta = np.argmax(n_buta)\n",
    "n, b, p = plt.hist(df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==1], alpha=1, bins=b_buta, histtype='step', label=\"carbon\", linewidth=2) \n",
    "bin_max_carb = np.argmax(n)\n",
    "# n, b, p = plt.hist(df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==2], alpha=1, bins=b_buta, histtype='step', label=\"polythene\", linewidth=2) \n",
    "# bin_max_poly = np.argmax(n)\n",
    "n, b, p = plt.hist(df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==3], alpha=1, bins=b_buta, histtype='step', label=\"ice\", linewidth=2)\n",
    "bin_max_ice = np.argmax(n)\n",
    "\n",
    "\n",
    "#Texts\n",
    "plt.text(0.05, 0.85, \"BUTANOL \\n Mode {:>10.3f} \\n Mean {:>10.3f} \\n $\\sigma$ {:>15.3f}\" \\\n",
    "         .format(b[bin_max_buta], df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==0].astype(float).mean(), \\\n",
    "                 df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==0].astype(float).std()), \\\n",
    "         fontsize=20, bbox=dict(facecolor='none', pad=5.0), transform=plt.gca().transAxes)\n",
    "\n",
    "plt.text(0.05, 0.73, \"CARBON \\n Mode {:>10.3f} \\n Mean {:>10.3f} \\n $\\sigma$ {:>15.3f}\" \\\n",
    "         .format(b[bin_max_carb], df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==1].astype(float).mean(), \\\n",
    "                 df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==1].astype(float).std()), \\\n",
    "         fontsize=20, bbox=dict(facecolor='none', pad=5.0), transform=plt.gca().transAxes)\n",
    "\n",
    "# plt.text(0.05, 0.61, \"POLYTHENE \\n Mode {:>10.3f} \\n Mean {:>10.3f} \\n $\\sigma$ {:>15.3f}\" \\\n",
    "#          .format(b[bin_max_poly], df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==2].astype(float).mean(), \\\n",
    "#                  df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==2].astype(float).std()), \\\n",
    "#          fontsize=20, bbox=dict(facecolor='none', pad=5.0), transform=plt.gca().transAxes)\n",
    "\n",
    "plt.text(0.05, 0.49, \"ICE \\n Mode {:>10.3f} \\n Mean {:>10.3f} \\n $\\sigma$ {:>15.3f}\" \\\n",
    "         .format(b[bin_max_ice], df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==3].astype(float).mean(), \\\n",
    "                 df_GMSH[\"mmsq_pi0\"][df_GMSH[\"T_fin\"]==3].astype(float).std()), \\\n",
    "         fontsize=20, bbox=dict(facecolor='none', pad=5.0), transform=plt.gca().transAxes)\n",
    "\n",
    "#Labels and lim\n",
    "plt.xlim(-1, 1)\n",
    "plt.xlabel(\"Missing mass sq. $[GeV^2/c^4]$\", fontsize=30)\n",
    "plt.ylabel(\"Counts $(x10^4)$\", fontsize=30)\n",
    "plt.xticks(fontsize=25)\n",
    "plt.yticks(fontsize=25)\n",
    "\n",
    "#Y-Axis Scaling\n",
    "def adjust_y_axis(x, pos):\n",
    "    return \"{:.0f}\".format(x/10000)\n",
    "plt.gca().yaxis.set_major_formatter(mpl.ticker.FuncFormatter(adjust_y_axis))\n",
    "\n",
    "#Grids\n",
    "plt.axes().xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.axes().yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator())\n",
    "plt.grid(b=True, which=\"major\", color=\"gray\", linewidth=1.0, linestyle=\"--\")\n",
    "plt.grid(b=True, which=\"minor\", color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "# plt.title(\"Predicted Missing Mass Sq $\\pi_0$: Butanol vs Carbon\")\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# g9a_mmsq_pred_ml.savefig(\"./run_period_1/g9a_mmsq_pred_ml\")\n",
    "# g9a_mmsq_pred_ml.savefig(\"./run_period_2/g9a_mmsq_pred_ml\")\n",
    "# g9a_mmsq_pred_ml.savefig(\"./run_period_3/g9a_mmsq_pred_ml\")\n",
    "# g9a_mmsq_pred_ml.savefig(\"./run_period_4_1//g9a_mmsq_pred_ml\")\n",
    "# g9a_mmsq_pred_ml.savefig(\"./run_period_5_1//g9a_mmsq_pred_ml\")\n",
    "# g9a_mmsq_pred_ml.savefig(\"./run_period_6_1//g9a_mmsq_pred_ml\")\n",
    "# g9a_mmsq_pred_ml.savefig(\"./run_period_7_1//g9a_mmsq_pred_ml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Build Model + Prediction (LLapi) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and Resume "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Low Energy Run Range  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save SUPER RAW (ELOSS + CM COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_1/df_GMSH_dstmaker_Ppi0_4_super_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_1/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_1/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial PlUS (ML + zvtx + SF)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_1/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save All (mmsq)\n",
    "# df_GMSH.to_pickle(\"./dstmakedstmaker_Ppi0_4_elossr_Ppi0_4/low_1/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Save SUPER RAW (ELOSS + CM COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_1/df_GMSH_dstmaker_Ppi0_4_super_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_1/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_1/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML + zvtx + SF)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_1/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read All (mmsq)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_1/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Low Energy Run Range  2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_2/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_2/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save Initial PlUS (ML + zvtx + SF)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_2/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save All (mmsq)\n",
    "# df_GMSH.to_pickle(\"./dstmakedstmaker_Ppi0_4_elossr_Ppi0_4/low_2/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_2/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_2/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_2/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read All (mmsq)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_2/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Low Energy Run Range  3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_3/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_3/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial PlUS (ML + zvtx + SF)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_3/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save All (mmsq)\n",
    "# df_GMSH.to_pickle(\"./dstmakedstmaker_Ppi0_4_elossr_Ppi0_4/low_3/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_3/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_3/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_3/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read All (mmsq)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_3/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Low Energy Run Range 4 - [0, 1.6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_4/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_4/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial PlUS (ML + zvtx + SF)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_4/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save All (mmsq)\n",
    "# df_GMSH.to_pickle(\"./dstmakedstmaker_Ppi0_4_elossr_Ppi0_4/low_4/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_4/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_4/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_4/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read All (mmsq)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_4/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Low Energy Run Range 5 - [0, 1.6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_5/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_5/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial PlUS (ML + zvtx + SF)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_5/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save All (mmsq)\n",
    "# df_GMSH.to_pickle(\"./dstmakedstmaker_Ppi0_4_elossr_Ppi0_4/low_5/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_5/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_5/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_5/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read All (mmsq)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_5/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Low Energy Run Range 6 - [0, 1.6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_6/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_6/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial PlUS (ML + zvtx + SF)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_6/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save All (mmsq)\n",
    "# df_GMSH.to_pickle(\"./dstmakedstmaker_Ppi0_4_elossr_Ppi0_4/low_6/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_6/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_6/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_6/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read All (mmsq)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_6/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Low Energy Run Range 7 - [0, 1.6] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_7/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_7/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial PlUS (ML + zvtx + SF)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/low_7/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save All (mmsq)\n",
    "# df_GMSH.to_pickle(\"./dstmakedstmaker_Ppi0_4_elossr_Ppi0_4/low_7/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_7/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_7/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_7/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read All (mmsq)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_7/df_GMSH_dstmaker_Ppi0_4_ALL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Run Range 4 - High Energy - (1.6, 2.4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ##Save SUPER RAW (ELOSS + CM COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_4/df_GMSH_dstmaker_Ppi0_4_super_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ##Save RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_4/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ##Save Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_4/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial PlUS (ML + zvtx + SF)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_4/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save after mmsq selection: mmsq_dict\n",
    "# mmsq = open(\"./dstmaker_Ppi0_4_eloss/high_4/mmsq_dict.pkl\", \"wb\")\n",
    "# pickle.dump(mmsq_dict, mmsq)\n",
    "# mmsq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Save SUPER RAW (ELOSS + CM COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_4/df_GMSH_dstmaker_Ppi0_4_super_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_4/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_4/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML + zvtx + SF)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_4/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read MMSQ selection: mmsq_dict\n",
    "mmsq       = open(\"./dstmaker_Ppi0_4_eloss/high_4/mmsq_dict.pkl\", \"rb\")\n",
    "mmsq_dict  = pickle.load(mmsq)\n",
    "mmsq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Run Range 5 - High Energy - (1.6, 2.4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ##Save SUPER RAW (ELOSS + CM COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_5/df_GMSH_dstmaker_Ppi0_4_super_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_5/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "## Save Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_5/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##Save Initial PlUS (ML + zvtx + SF)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_5/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save after mmsq selection: mmsq_dict\n",
    "# mmsq = open(\"./dstmaker_Ppi0_4_eloss/high_5/mmsq_dict.pkl\", \"wb\")\n",
    "# pickle.dump(mmsq_dict, mmsq)\n",
    "# mmsq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Save SUPER RAW (ELOSS + CM COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_5/df_GMSH_dstmaker_Ppi0_4_super_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_5/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_5/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML + zvtx + SF)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_5/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read MMSQ selection: mmsq_dict\n",
    "mmsq       = open(\"./dstmaker_Ppi0_4_eloss/high_5/mmsq_dict.pkl\", \"rb\")\n",
    "mmsq_dict  = pickle.load(mmsq)\n",
    "mmsq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Run Range 6 - High Energy - (1.6, 2.4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ##Save SUPER RAW (ELOSS + CM COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_6/df_GMSH_dstmaker_Ppi0_4_super_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ##Save RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_6/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_6/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial PlUS (ML + zvtx + SF)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_6/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save after mmsq selection: mmsq_dict\n",
    "# mmsq = open(\"./dstmaker_Ppi0_4_eloss/high_6/mmsq_dict.pkl\", \"wb\")\n",
    "# pickle.dump(mmsq_dict, mmsq)\n",
    "# mmsq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Save SUPER RAW (ELOSS + CM COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_6/df_GMSH_dstmaker_Ppi0_4_super_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_6/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_6/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_6/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read MMSQ selection: mmsq_dict\n",
    "mmsq       = open(\"./dstmaker_Ppi0_4_eloss/high_6/mmsq_dict.pkl\", \"rb\")\n",
    "mmsq_dict  = pickle.load(mmsq)\n",
    "mmsq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Run Range 7 - High Energy - (1.6, 2.4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save SUPER RAW (ELOSS + CM COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_7/df_GMSH_dstmaker_Ppi0_4_super_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_7/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Save Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_7/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Save Initial PlUS (ML + zvtx + SF)\n",
    "# df_GMSH.to_pickle(\"./dstmaker_Ppi0_4_eloss/high_7/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save after mmsq selection: mmsq_dict\n",
    "# mmsq = open(\"./dstmaker_Ppi0_4_eloss/high_7/mmsq_dict.pkl\", \"wb\")\n",
    "# pickle.dump(mmsq_dict, mmsq)\n",
    "# mmsq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Save SUPER RAW (ELOSS + CM COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_7/df_GMSH_dstmaker_Ppi0_4_super_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read RAW (WeiMome + HeBath + Fiducial + SOME COMPUTES)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_7/df_GMSH_dstmaker_Ppi0_4_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial (LowMome + proton + photon + tof) - FOR ML\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_7/df_GMSH_dstmaker_Ppi0_4_initial.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML + zvtx + SF)\n",
    "df_GMSH = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/high_7/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read MMSQ selection: mmsq_dict\n",
    "mmsq       = open(\"./dstmaker_Ppi0_4_eloss/high_7/mmsq_dict.pkl\", \"rb\")\n",
    "mmsq_dict  = pickle.load(mmsq)\n",
    "mmsq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data Save/Resume for all runes COMBINED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### For SF + DF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML + zvtx + SF)\n",
    "df_GMSH_1= pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_1/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH_2 = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_2/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH_3 = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_3/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH_4 = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_4/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH_5 = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_5/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH_6 = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_6/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read Initial PlUS (ML* + zvtx + SF)\n",
    "df_GMSH_7 = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_7/df_GMSH_dstmaker_Ppi0_4_initial_plus.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Combine\n",
    "df_GMSH = pd.concat([df_GMSH_1, df_GMSH_2, df_GMSH_3, df_GMSH_4, df_GMSH_5, df_GMSH_6, df_GMSH_7], \\\n",
    "                     ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Drop unneeded columns to speed up computation\n",
    "column_drop_list = []\n",
    "columns          = df_GMSH.columns\n",
    "needed_columns   = [\"cthe_cm\", \"epho\", \"el_pc_mmsq_pi0\", \"T_fin\"]\n",
    "drop_list        = []\n",
    "\n",
    "for i in columns:\n",
    "    if (i not in needed_columns):\n",
    "        drop_list.append(i)\n",
    "        \n",
    "#Drop-\n",
    "df_GMSH.drop(columns=drop_list, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Low Energy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read df from each runs (MUST, BUT NOT YET)\n",
    "df_GMSH = pd.DataFrame()\n",
    "\n",
    "for i in range(1, 8):\n",
    "    df_GMSH_i = pd.read_pickle(\"./dstmaker_Ppi0_4_eloss/low_{:d}/df_GMSH_dstmaker_Ppi0_4_initial.pkl\".format(i))[[\"epho\", \"cthe_cm\", \"el_pc_mmsq_pi0\"]]\n",
    "    df_GMSH = df_GMSH.append(df_GMSH_i, ignore_index=True)\n",
    "\n",
    "df_GMSH = df_GMSH.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Plot all events' mmsq (MUST)\n",
    "global_mmsq = plt.figure(figsize=(15, 10))\n",
    "\n",
    "#Histogram\n",
    "n, b, p = plt.hist(df_GMSH[\"el_pc_mmsq_pi0\"], bins=6500, label=\"$M_X^2$\", alpha=0.7, color=\"#4C72B0\")\n",
    "\n",
    "#Stats\n",
    "bin_max = np.argmax(n)\n",
    "peak    = b[bin_max]\n",
    "mean    = df_GMSH[\"el_pc_mmsq_pi0\"].mean()\n",
    "stddev  = df_GMSH[\"el_pc_mmsq_pi0\"].std()\n",
    "\n",
    "#===================================================================================================\n",
    "#Selection range\n",
    "#    -SAVE to be used for dropping events\n",
    "frst_ln = peak - 0.5*stddev\n",
    "scnd_ln  = peak + 0.5*stddev\n",
    "#===================================================================================================\n",
    "\n",
    "#Draw lines\n",
    "plt.axvline(first_ln, linestyle=\"-\", linewidth=3, alpha=0.5, color=\"#C44E52\")\n",
    "plt.axvline(scnd_ln,  linestyle=\"--\", linewidth=3, alpha=0.5, color=\"#C44E52\")\n",
    "\n",
    "#Texts\n",
    "plt.text(0.05, 0.85, \" {:<12} {:>10.3f} \\n {:<12} {:>10.3f} \\n {:<21} {:>10.3f}\" \\\n",
    "         .format(\"peak\", peak, \"mean\", mean, \"$\\sigma$\", stddev), \\\n",
    "         fontsize=15, bbox=dict(facecolor='none', pad=5.0), transform=plt.gca().transAxes)\n",
    "\n",
    "#Grids\n",
    "plt.axes().xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "plt.axes().yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "plt.grid(b=True, which=\"major\", color=\"gray\", linewidth=1.0, linestyle=\"--\")\n",
    "plt.grid(b=True, which=\"minor\", color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "\n",
    "#Y-Axis Scaling\n",
    "def adjust_y_axis(x, pos):\n",
    "    return \"{:.0f}\".format(x/10000)\n",
    "plt.gca().yaxis.set_major_formatter(mpl.ticker.FuncFormatter(adjust_y_axis))\n",
    "\n",
    "#Labels, ticks, lim\n",
    "plt.xlim(-1.0, 1.0)\n",
    "plt.xlabel(\"$M_X^2$ $[GeV^2/c^4]$\", fontsize=15)\n",
    "plt.ylabel(\"Counts $(x10^4)$\", fontsize=15)\n",
    "\n",
    "#Legends\n",
    "custom_label = [mpl.lines.Line2D([0], [0], color=\"#C44E52\", alpha=0.7, linewidth=3, \\\n",
    "                                 label=\"peak - $\\sigma$    = {:.3f}\".format(frst_ln), linestyle=\"-\"), \n",
    "                mpl.lines.Line2D([0], [0], color=\"#C44E52\", alpha=0.7, linewidth=3, \\\n",
    "                                 label=\"peak + $\\sigma$   = {:.3f}\".format(scnd_ln), linestyle=\"--\")]\n",
    "plt.legend(handles=custom_label, fontsize=15, loc=\"upper right\")\n",
    "\n",
    "# plt.legend()\n",
    "plt.show()\n",
    "global_mmsq.savefig(\"./binning_global_mmsq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Drop events outside of +/- sigma (MUST)\n",
    "df_GMSH.drop(df_GMSH[(df_GMSH[\"el_pc_mmsq_pi0\"] < frst_ln) | (df_GMSH[\"el_pc_mmsq_pi0\"] > scnd_ln)].index, \\\n",
    "             inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Binning Method 1 (MUST)\n",
    "bin_partition_eg_perc = [i/20 for i in range(0, 21, 1)]\n",
    "bin_pos_eg_list    = df_GMSH[\"epho\"].quantile(bin_partition_eg_perc).tolist()\n",
    "epho_bins          = [round(i, 4) for i in bin_pos_eg_list]\n",
    "\n",
    "#cos_bins are dict now\n",
    "cos_bins = {}\n",
    "bin_partition_cos_perc = [i/10 for i in range(0, 11, 1)]\n",
    "\n",
    "#Partitions\n",
    "for i in range(len(epho_bins)-1):\n",
    "    #cos binning per epho bin\n",
    "    bin_pos_cos_list = df_GMSH[\"cthe_cm\"][(epho_bins[i] <= df_GMSH[\"epho\"]) & \\\n",
    "                                          (df_GMSH[\"epho\"] <= epho_bins[i+1])] \\\n",
    "                                         .quantile(bin_partition_cos_perc).tolist()\n",
    "\n",
    "    #Into cos_bins dict\n",
    "    cos_bins[\"Eg_{:07.3f}\".format(epho_bins[i])] = [round(i, 4) for i in bin_pos_cos_list]\n",
    "\n",
    "#Print\n",
    "print(bin_partition_eg_perc)\n",
    "print(len(bin_partition_eg_perc))\n",
    "print(bin_partition_cos_perc)\n",
    "print(len(bin_partition_cos_perc))\n",
    "print(\"epho_bins = \", epho_bins)\n",
    "print(\"len(epho_bins) = \", len(epho_bins))\n",
    "#Print cos bins for each epho bins\n",
    "for i in sorted(cos_bins.keys()):\n",
    "    print(i, cos_bins[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#epho vs angle (CHECK)\n",
    "binning = plt.figure(figsize=(15, 15))\n",
    "\n",
    "#Hist\n",
    "plt.hist2d(df_GMSH[\"cthe_cm\"], df_GMSH[\"epho\"], bins=500, cmap=\"jet\", cmin=0, \\\n",
    "           norm=mpl.colors.LogNorm())\n",
    "\n",
    "#Lines to indicate epho bins\n",
    "for i, k in zip(sorted(cos_bins.keys()), range(len(epho_bins))):\n",
    "    for j in range(len(cos_bins[i])):\n",
    "        plt.hlines(y=epho_bins[k], xmin=cos_bins[i][0], xmax=cos_bins[i][-1], \\\n",
    "                   linestyle=\"-\", linewidth=1.75, color=\"black\")\n",
    "        plt.hlines(y=epho_bins[k+1], xmin=cos_bins[i][0], xmax=cos_bins[i][-1], \\\n",
    "                   linestyle=\"-\", linewidth=1.75, color=\"black\")\n",
    "        \n",
    "#Manually draw last epho line\n",
    "plt.hlines(y=epho_bins[-1], xmin=cos_bins[sorted(cos_bins.keys())[-1]][0], \\\n",
    "           xmax=cos_bins[sorted(cos_bins.keys())[-1]][-1], \\\n",
    "           linestyle=\"-\", linewidth=1.75, color=\"black\")\n",
    "        \n",
    "        \n",
    "#Lines to indicate cos bins    \n",
    "for i, k in zip(sorted(cos_bins.keys()), range(len(epho_bins)-1)):\n",
    "    for j in range(len(cos_bins[i])):\n",
    "        plt.vlines(x=cos_bins[i][j], ymin=epho_bins[k], ymax=epho_bins[k+1], \\\n",
    "                   linestyle=\"-\", linewidth=1.75, color=\"black\")\n",
    "    \n",
    "#lim, label, ticks    \n",
    "plt.xlim(-1.1, 1.1)\n",
    "plt.ylim(0.25, 1.75)\n",
    "plt.xlabel(\"$cos\\\\theta_{cm}$\", fontsize=40)\n",
    "plt.ylabel(\"$E_{\\gamma}$\", fontsize=40)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "\n",
    "#Grids\n",
    "plt.axes().xaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "plt.axes().yaxis.set_minor_locator(mpl.ticker.AutoMinorLocator(5))\n",
    "plt.grid(b=True, which=\"major\", color=\"gray\", linewidth=0.5, linestyle=\"--\")\n",
    "plt.grid(b=True, which=\"minor\", color=\"gray\", linewidth=0.25, linestyle=\"--\")\n",
    "\n",
    "cbaxes = binning.add_axes([0.91, 0.125, 0.02, 0.755])   # x_pos, y_pos, width, length\n",
    "cbaxes.tick_params(labelsize=20)\n",
    "plt.colorbar(cax=cbaxes)\n",
    "plt.show\n",
    "binning.savefig(\"./binning\")\n",
    "# binning.savefig(\"./binning_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Binning method 1 # of events in each bins (CHECK)\n",
    "# for i, j in zip(range(len(epho_bins)-1), sorted(cos_bins.keys())):\n",
    "#     print(\"==============================\", epho_bins[i], \"=============================\")\n",
    "#     for k in range(len(cos_bins[j])-1):\n",
    "\n",
    "#         print(len(df_GMSH[(epho_bins[i]   <= df_GMSH[\"epho\"])    & (df_GMSH[\"epho\"]    <= epho_bins[i+1]) & \\\n",
    "#                           (cos_bins[j][k] <= df_GMSH[\"cthe_cm\"]) & (df_GMSH[\"cthe_cm\"] <= cos_bins[j][k+1])]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Binning Method 2 (NONEED)\n",
    "# bin_partition_eg_perc = [i/20 for i in range(0, 21, 1)]\n",
    "# bin_pos_eg_list    = df_GMSH[\"epho\"].quantile(bin_partition_eg_perc).tolist()\n",
    "# epho_bins          = [round(i, 4) for i in bin_pos_eg_list]\n",
    "\n",
    "# #Cos binning\n",
    "# bin_partition_cos_perc = [i/10 for i in range(0, 11, 1)]\n",
    "# bin_pos_cos_list       = df_GMSH[\"cthe_cm\"].quantile(bin_partition_cos_perc).tolist()\n",
    "# cos_bins               = [round(i, 4) for i in bin_pos_cos_list]\n",
    "\n",
    "# #Print\n",
    "# print(bin_partition_eg_perc)\n",
    "# print(len(bin_partition_eg_perc))\n",
    "# print(bin_partition_cos_perc)\n",
    "# print(len(bin_partition_cos_perc))\n",
    "# print(\"epho_bins = \", epho_bins)\n",
    "# print(\"len(epho_bins) = \", len(epho_bins))\n",
    "# print(\"cos_binss = \", cos_bins)\n",
    "# print(\"len(cos_bins) = \", len(cos_bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Binning method 2 # of events in each bins (NONEED)\n",
    "# for i in range(len(epho_bins)-1):\n",
    "    \n",
    "#     print(\"==============================\", epho_bins[i], \"=============================\")\n",
    "#     for j in range(len(cos_bins)-1):\n",
    "#         print(len(df_GMSH[(epho_bins[i] <= df_GMSH[\"epho\"])    & (df_GMSH[\"epho\"]    <= epho_bins[i+1]) & \\\n",
    "#                           (cos_bins[j]  <= df_GMSH[\"cthe_cm\"]) & (df_GMSH[\"cthe_cm\"] <= cos_bins[j+1])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### High Energy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Save & Read last Binning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save epho\n",
    "# epho_dict = {\"epho_bins\": epho_bins}\n",
    "# df_epho_dict = pd.DataFrame(epho_dict)\n",
    "\n",
    "# #save to csv\n",
    "# df_epho_dict.to_csv(\"./results_Binning/epho_bins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Save cos_bins dict\n",
    "# with open(\"./results_Binning/cos_bins\", \"w\") as f:\n",
    "#     writer = csv.writer(f, delimiter=\"\\t\")\n",
    "    \n",
    "#     for key in sorted(cos_bins.keys()):\n",
    "#         writer.writerow([key] + cos_bins[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read\n",
    "df_epho_dict = pd.read_csv(\"./results_Binning/epho_bins\", index_col=0)\n",
    "#Into epho_bins list\n",
    "epho_bins = df_epho_dict[df_epho_dict.columns[0]].tolist()\n",
    "\n",
    "print(epho_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Read cos_bins dict\n",
    "df       = pd.read_csv(\"./results_Binning/cos_bins\", index_col=0, delimiter=\"\\t\", header=None)\n",
    "cos_bins = df.transpose().to_dict(orient=\"list\")\n",
    "\n",
    "#Print\n",
    "for i in sorted(cos_bins.keys()):\n",
    "    for j in range(len(cos_bins[i])):\n",
    "        cos_bins[i] = [round(a, 4) for a in cos_bins[i]]\n",
    "    print(i, cos_bins[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Drop unused columns + Rename "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_GMSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Unwatned columns list\n",
    "columns_list = ['scPdHt', 'beta_cm', 'gamma_cm','pz_cm', 'p_cm_abs', 'theta_cm', \"T_pred\", \"ice_pred\", \"phi_sec\", \\\n",
    "                \"el_pc_pz\"]\n",
    "\n",
    "#Unwatned columns list\n",
    "# columns_list = [\"TRIGBITS\", \"runNum\"]\n",
    "\n",
    "#Unwanted column list\n",
    "print(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Remove\n",
    "df_GMSH.drop(columns=columns_list, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_GMSH.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_GMSH.rename(columns={\"el_px\":\"px\", \"el_py\":\"py\", \"el_pz\":\"pz\", \"el_p_abs\":\"p_abs\", \"el_E\":\"E\", \"el_mmsq_pi0\":\"mmsq_pi0\", \\\n",
    "                        \"el_beta\":\"beta\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Reduce df memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_GMSH.memory_usage().sum() / 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Reduce memory usage by changing dtype\n",
    "def reduce_mem_usage(df):\n",
    "\n",
    "    \"\"\" \n",
    "    iterate through all the columns of a dataframe and \n",
    "    modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(('Memory usage of dataframe is {:.2f}' \n",
    "                     'MB').format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "#         if (col_type == \"category\"):\n",
    "#             continue\n",
    "\n",
    "        if (col_type != object):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max <\\\n",
    "                  np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max <\\\n",
    "                   np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max <\\\n",
    "                   np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max <\\\n",
    "                   np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max <\\\n",
    "                   np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max <\\\n",
    "                   np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "#         else:\n",
    "#             df[col] = df[col].astype('category')\n",
    "    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(('Memory usage after optimization is: {:.2f}' \n",
    "                              'MB').format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \n",
    "                                             / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in df_GMSH.columns:\n",
    "    print(i, \"\\t\",df_GMSH[i].dtype)\n",
    "    print(df_GMSH[i].dtype.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Change CategoricalDtype to int\n",
    "df_GMSH[\"pid\"] = df_GMSH[\"pid\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Apply reduce_mem_usage fn.\n",
    "df_GMSH = reduce_mem_usage(df_GMSH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "355px",
    "width": "428.984px"
   },
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "",
   "title_sidebar": "",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
